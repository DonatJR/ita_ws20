{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jessi\\documents\\studium\\ws20_21\\text analytics\\ita_ws20\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(1, '../src/utils')\n",
    "import ipdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "from sklearn.manifold import TSNE\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "from data import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jessi\\documents\\studium\\ws20_21\\text analytics\\ita_ws20\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "num_topics = 50\n",
    "use_title = True\n",
    "stemming = True\n",
    "lemmatization = True\n",
    "lib = \"spacy\"\n",
    "\n",
    "input_path = Path(\"../src/data/data_jmlr_vol13-21.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "We also had ```gensim``` supported for preprocessing, but realized that even in their official docs, they make it a point that this should not be a use case! After having odd problems with their lemmatization routines (and ```pattern```), we just dropped it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jessi\\documents\\studium\\ws20_21\\text analytics\\ita_ws20\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "with open(input_path, encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "data_df = pd.json_normalize(data['papers'])\n",
    "corpus = data_df[\"abstract\"]\n",
    "if use_title:\n",
    "    corpus = data_df[\"title\"] + \" \" + corpus \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jessi\\documents\\studium\\ws20_21\\text analytics\\ita_ws20\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 entries of corpus, due to nan ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tokenization ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "880it [01:05, 14.37it/s]"
     ]
    }
   ],
   "source": [
    "corpus = preprocessing(\n",
    "    corpus,\n",
    "    lib=lib,\n",
    "    stemming=stemming,\n",
    "    lemmatization=lemmatization,\n",
    "    min_word_len=2,\n",
    "    max_word_len=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(corpus[\"token\"]) \n",
    "BoW_corpus = [dictionary.doc2bow(text) for text in corpus[\"token\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(BoW_corpus)\n",
    "corpus_tfidf = tfidf[BoW_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lsi_tfidf = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=num_topics)# train model\n",
    "lsi_tfidf[corpus_tfidf[1]]  # apply model to  document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lsi_bow = models.LsiModel(BoW_corpus, id2word=dictionary, num_topics=num_topics)\n",
    "lsi_bow[BoW_corpus[1]]  # apply model to  document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# LDA model training \n",
    "lda_model = models.ldamodel.LdaModel(corpus=corpus_tfidf,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=num_topics,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=100,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_str = f\"(Preprocessing with {lib}, Stemming = {stemming}, Lemmatization = {lemmatization})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_count = 0\n",
    "for abstract in data_df[\"abstract\"]:\n",
    "    if abstract:\n",
    "        abstract_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \" + str(len(data_df[\"abstract\"])) + f\" Papers. {str(abstract_count)} of them have Abstracts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for keyword in data_df[\"keywords\"]:\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"The Dataset contains {len(data_df)} Papers\")\n",
    "count_keywords = 0\n",
    "all_keywords = []\n",
    "for keyword in data_df[\"keywords\"]:\n",
    "    if keyword and keyword[0]:\n",
    "        count_keywords += 1\n",
    "        all_keywords = all_keywords + keyword\n",
    "print(f\"{count_keywords} of them contain Keywords.\")\n",
    "print(f\"There are {len(all_keywords)} Keywords. {len(set(all_keywords))} of them are unique.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(dictionary.token2id)#token -> tokenId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(dictionary.dfs) # token_id -> how many documents contain this token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(BoW_corpus)# list of (token_id, token_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(corpus, label, method):\n",
    "    all_words = {}\n",
    "    for doc in corpus:\n",
    "        for word_id, score in doc:\n",
    "            word = dictionary.id2token[word_id]\n",
    "            if word in all_words:\n",
    "                if method == \"TF-IDF\":\n",
    "                    all_words[word] += score / len(corpus)\n",
    "                else:\n",
    "                    all_words[word] += score\n",
    "            else:\n",
    "                if method == \"TF-IDF\":\n",
    "                    all_words[word] = score / len(corpus)\n",
    "                else:\n",
    "                    all_words[word] = score\n",
    "    df = pd.DataFrame(list(all_words.items()),\n",
    "                       columns=['term', label])\n",
    "    return df.sort_values(by=label, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(top_words, method, legend):\n",
    "    words_plot = top_words.plot.bar(x='term', y=legend, rot=0, fontsize= 16, figsize= (30, 10))\n",
    "    words_plot.set_xlabel(\"Term\", fontsize= 20)\n",
    "    words_plot.set_ylabel(method, fontsize= 20)\n",
    "    words_plot.set_title(f\"Top words with {method} {preprocessing_str}\", fontsize= 30)\n",
    "    words_plot.yaxis.get_major_formatter().set_scientific(False)\n",
    "    fig = words_plot.get_figure()\n",
    "    fig.savefig(Path(f'imgs/top_words_{method}_preprocessing_{lib}_stemming_{stemming}_lemmatization_{lemmatization}_num_topics_{num_topics}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(get_top_words(corpus_tfidf, \"weight\", \"TF-IDF\"), \"TF-IDF\", \"weight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(get_top_words(BoW_corpus, \"count\", \"BoW\"), \"Bow\", \"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lsi_tfidf.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lsi_bow.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_2d_space(corpus, method, corpus_name, method_name, use_tsne=False):\n",
    "\n",
    "    if isinstance(method, models.ldamodel.LdaModel):\n",
    "        documents_2d_1=[x[0][0][1] for x in method[corpus] if x]\n",
    "        documents_2d_2=[x[0][1][1] for x in list(method[corpus]) if x]\n",
    "    else:\n",
    "        documents_2d_1=[x[0][1] for x in method[corpus] if x]\n",
    "        documents_2d_2=[x[1][1] for x in list(method[corpus]) if x]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "  # Get topic weights\n",
    "    topic_weights = []\n",
    "    for i, row_list in enumerate(method[corpus]):\n",
    "        if row_list:\n",
    "            if isinstance(method, models.ldamodel.LdaModel):\n",
    "                topic_weights.append([w for i, w in row_list[0]])\n",
    "            else:\n",
    "                topic_weights.append([w for i, w in row_list])\n",
    "\n",
    "    # Array of topic weights    \n",
    "    arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "    # Dominant topic number in each doc\n",
    "    topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "    if use_tsne:\n",
    "        tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99)\n",
    "        tsne = tsne_model.fit_transform(arr)\n",
    "        documents_2d_1 = tsne[:,0]\n",
    "        documents_2d_2 = tsne[:,1]\n",
    "    ax.set_title(f\"{corpus_name} in 2D-Space with {method_name} {preprocessing_str}\")\n",
    "    ax.scatter(documents_2d_1, documents_2d_2, c=topic_num, s=80 ,alpha=0.8)\n",
    "    plt.savefig(Path(f'imgs/{method_name}_{corpus_name}_preprocessing_{lib}_stemming_{stemming}_lemmatization_{lemmatization}_num_topics_{num_topics}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_space(BoW_corpus, lsi_bow, \"BoW\", \"LSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_space(corpus_tfidf, lsi_tfidf, \"TF-IDF\", \"LSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_space(corpus_tfidf, lda_model, \"TF-IDF\", \"LDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_space(corpus_tfidf, lda_model, \"TF-IDF\", \"LDA with TSNE\", use_tsne=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus_tfidf, dictionary=lda_model.id2word, mds='mmds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vis"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
